{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B/n Testing Statistical Significance Calculator\n",
    "In the following scripts you will find how to calculate if the observed change has statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1**. ***A/B/n Test Statistical Calculator for Discrete Variables***\n",
    "Use only for discrete variables, such as:\n",
    "- **UI change**: Test different layouts of a landing page to see which one increases user engagement, measured as the ad-to-cart click though rate\n",
    "- **Email marketing**: Test different email subject lines or content to determine which version maximizes the email opening by the recipient, or webinar subscription.\n",
    "- **Feature rollout**: Measure the impact of different user interface changes on impulsive purchases.\n",
    "- **Pricing changes**: Evaluate the effect of different pricing structures on getting the sale.\n",
    "\n",
    "Needs to have normal distribution. Otherwise another method should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ##### Create a function to calculate statistical significance of control groups and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Create a function to calculate the sample size of tests with discrete values\n",
    "def analyze_abn_test_discrete(data):\n",
    "    \"\"\"\n",
    "        # Explanation:\n",
    "            data: A dictionary following the following formatting:\n",
    "                    data = {\n",
    "                'Control': [387, 4113],     # [clicks, total views]\n",
    "                'Test 1': [30, 216],        # [clicks, total views]\n",
    "                'Test 2': [90, 500],        # [clicks, total views]\n",
    "                'Test 3': [60, 300]         # [clicks, total views]\n",
    "            }\n",
    "\n",
    "            - z_stat: The z-statistic calculated to compare the two groups.\n",
    "            - p_value: The p-value corresponding to the z-statistic, used to assess statistical significance.\n",
    "\n",
    "\n",
    "        # Key points to consider:\n",
    "            - If the p-value is smaller than 0.05, you reject the null hypothesis and conclude that there is a significant difference between the groups.\n",
    "            - If the p-value is greater than 0.05, you fail to reject the null hypothesis and conclude that there is no significant difference.\n",
    "\n",
    "        # Example data: successes and total sample sizes for control and test 1\n",
    "            data = {\n",
    "                'Control': [387, 4113],     # [clicks, total views]\n",
    "                'Test 1': [30, 216]         # [clicks, total views]\n",
    "                }\n",
    "\n",
    "            Result:\n",
    "                Conversion rates:\n",
    "                    * Control: 9.41%\n",
    "                    * Test 1: 13.89%\n",
    "\n",
    "                Comparison of Control vs. Test 1:\n",
    "                    * z-statistic: 2.1751\n",
    "                    * p-value: 0.0296\n",
    "                    * Test 1 shows a significant improvement over control by 47.61%.\n",
    "\n",
    "                The best-performing test is **Test 1** with a conversion rate of 13.89%.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate click-through rates for each test\n",
    "    ctr = {test: clicks / total for test, (clicks, total) in data.items()}\n",
    "    print(\"Conversion rates:\")\n",
    "    for test, rate in ctr.items():\n",
    "        print(f\"    * {test}: {rate:.2%}\")\n",
    "    \n",
    "    # Conduct pairwise z-tests between each test and the control\n",
    "    control_clicks, control_total = data['Control']\n",
    "    for test, (clicks, total) in data.items():\n",
    "        if test != 'Control':\n",
    "            count = np.array([clicks, control_clicks])\n",
    "            nobs = np.array([total, control_total])\n",
    "            z_stat, p_value = proportions_ztest(count, nobs)\n",
    "            \n",
    "            improvement = (ctr[test] - ctr['Control']) / ctr['Control'] * 100\n",
    "            \n",
    "            print(f\"\\nComparison of Control vs. {test}:\")\n",
    "            print(f\"    * z-statistic: {z_stat:.4f}\")\n",
    "            print(f\"    * p-value: {p_value:.4f}\")\n",
    "            if p_value < 0.05:\n",
    "                if improvement > 0:\n",
    "                    print(f\"    * {test} shows a significant improvement over control by {improvement:.2f}%.\")\n",
    "                else:\n",
    "                    print(f\"    * {test} shows a significant worsening over control by {improvement:.2f}%.\")\n",
    "            else:\n",
    "                print(f\"    * {test} does not show a significant improvement over control.\")\n",
    "    \n",
    "    # Find the best-performing test by conversion\n",
    "    best_test = max(ctr, key=ctr.get)\n",
    "    print(f\"\\nThe best-performing test is **{best_test}** with a conversion rate of {ctr[best_test]:.2%}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ##### Input the tests results, and run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rates:\n",
      "    * Control: 9.41%\n",
      "    * Test 1: 13.89%\n",
      "    * Test 2: 18.00%\n",
      "    * Test 3: 20.00%\n",
      "\n",
      "Comparison of Control vs. Test 1:\n",
      "    * z-statistic: 2.1751\n",
      "    * p-value: 0.0296\n",
      "    * Test 1 shows a significant improvement over control by 47.61%.\n",
      "\n",
      "Comparison of Control vs. Test 2:\n",
      "    * z-statistic: 5.9572\n",
      "    * p-value: 0.0000\n",
      "    * Test 2 shows a significant improvement over control by 91.30%.\n",
      "\n",
      "Comparison of Control vs. Test 3:\n",
      "    * z-statistic: 5.8696\n",
      "    * p-value: 0.0000\n",
      "    * Test 3 shows a significant improvement over control by 112.56%.\n",
      "\n",
      "The best-performing test is **Test 3** with a conversion rate of 20.00%.\n"
     ]
    }
   ],
   "source": [
    "    #### Input parameters to calculate your sample size ####\n",
    "data = {\n",
    "    'Control': [387, 4113],     # [clicks, total views]\n",
    "    'Test 1': [30, 216],        # [clicks, total views]\n",
    "    'Test 2': [90, 500],        # [clicks, total views]\n",
    "    'Test 3': [60, 300]         # [clicks, total views]\n",
    "    }\n",
    "            \n",
    "    #### Run the function and print results ####\n",
    "analyze_abn_test_discrete(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2**. ***A/B/n Test Statistical Calculator for Continuous Variables***\n",
    "\n",
    "Use only for continuous variables, such as:\n",
    "- **UI change**: Test different layouts of a landing page to see which one increases user engagement, measured as the average time spent on the page.\n",
    "- **Email marketing**: Test different email subject lines or content to determine which version maximizes the time recipients spend reading the email.\n",
    "- **Feature rollout**: Measure the impact of different user interface changes on user session duration.\n",
    "- **Pricing changes**: Evaluate the effect of different pricing structures on the time users spend on pricing pages or the checkout process.\n",
    "\n",
    "Needs to have normal distribution. Otherwise another method should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ##### Create a function to calculate statistical significance of control groups and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "# Create a function to calculate the sample size of tests with continous values\n",
    "def analyze_abn_test_continous(control_mean, control_std, control_n, variations_data):\n",
    "    \"\"\"\n",
    "    Compares the performance of variations against a control group for a continuous variable.\n",
    "    Uses a two-tailed t-test with known means and standard deviations.\n",
    "    \n",
    "    Parameters:\n",
    "    control_mean (float): Mean of the control group.\n",
    "    control_std (float): Standard deviation of the control group.\n",
    "    control_n (int): Sample size of the control group.\n",
    "    variations_data (list of tuples): Each tuple contains (mean, std_dev, n) for each variation.\n",
    "    \n",
    "\n",
    "    # Example data: successes and total sample sizes for control and test 1\n",
    "        control_mean = 50  # Control group mean\n",
    "        control_std = 10   # Control group standard deviation\n",
    "        control_n = 1000   # Control group sample size\n",
    "\n",
    "        variations_data = [\n",
    "            (52, 10, 800)  # Test 1 (mean, std, sample size)\n",
    "\n",
    "    Result:\n",
    "        Control Group Mean: 50.0000, Standard Deviation: 10.0000, Sample Size: 1000\n",
    "\n",
    "        Test 1 Mean: 52.0000, Standard Deviation: 10.0000, Sample Size: 800\n",
    "            * t-statistic: 4.2164\n",
    "            * p-value: 0.0000\n",
    "            * Statistically significant difference: 2.0000\n",
    "\n",
    "        The best performing variation is Test 1, with a mean improvement of 2.0000.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Control Group Mean: {control_mean:.4f}, Standard Deviation: {control_std:.4f}, Sample Size: {control_n}\")\n",
    "    \n",
    "    best_p_value = 1  # Start with an initial large p-value\n",
    "    best_difference = 0  # Best observed difference in means\n",
    "    best_variant = None  # Best performing test\n",
    "\n",
    "    # Iterate over all variations\n",
    "    for idx, (mean_variation, std_variation, n_variation) in enumerate(variations_data):\n",
    "        # Calculate the standard error\n",
    "        se = math.sqrt((control_std**2 / control_n) + (std_variation**2 / n_variation))\n",
    "        \n",
    "        # Calculate the t-statistic\n",
    "        t_stat = (mean_variation - control_mean) / se\n",
    "        \n",
    "        # Calculate the degrees of freedom (using Welch-Satterthwaite equation)\n",
    "        df = ( (control_std**2 / control_n + std_variation**2 / n_variation)**2 ) / \\\n",
    "            ( ( (control_std**2 / control_n)**2 / (control_n - 1) ) + ( (std_variation**2 / n_variation)**2 / (n_variation - 1) ) )\n",
    "        \n",
    "        # Calculate the p-value for a two-tailed test\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=df))\n",
    "        \n",
    "        # Print results for this variation\n",
    "        print(f\"\\nTest {idx + 1} Mean: {mean_variation:.4f}, Standard Deviation: {std_variation:.4f}, Sample Size: {n_variation}\")\n",
    "        print(f\"    * t-statistic: {t_stat:.4f}\")\n",
    "        print(f\"    * p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Check if this variant shows a significant difference from the control\n",
    "        if p_value < 0.05:\n",
    "            mean_difference = (mean_variation - control_mean)\n",
    "            print(f\"    * Statistically significant difference: {mean_difference:.4f}\")\n",
    "            \n",
    "            # Track the best variant based on the absolute difference\n",
    "            if abs(mean_difference) > abs(best_difference):\n",
    "                best_difference = mean_difference\n",
    "                best_variant = idx + 1\n",
    "        else:\n",
    "            print(\"    * No significant difference compared to the control group.\")\n",
    "\n",
    "    # Conclusion: Best performing variant\n",
    "    if best_variant is not None:\n",
    "        print(f\"\\nThe best performing variation is **Test {best_variant}**, with a mean improvement of {best_difference:.4f}.\")\n",
    "    else:\n",
    "        print(\"\\nNo variation significantly improved over the control group.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ##### Input the tests results, and run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Group Mean: 50.0000, Standard Deviation: 10.0000, Sample Size: 1000\n",
      "\n",
      "Test 1 Mean: 52.0000, Standard Deviation: 10.0000, Sample Size: 800\n",
      "    * t-statistic: 4.2164\n",
      "    * p-value: 0.0000\n",
      "    * Statistically significant difference: 2.0000\n",
      "\n",
      "Test 2 Mean: 60.0000, Standard Deviation: 50.0000, Sample Size: 1000\n",
      "    * t-statistic: 6.2017\n",
      "    * p-value: 0.0000\n",
      "    * Statistically significant difference: 10.0000\n",
      "\n",
      "Test 3 Mean: 48.0000, Standard Deviation: 50.0000, Sample Size: 600\n",
      "    * t-statistic: -0.9682\n",
      "    * p-value: 0.3333\n",
      "    * No significant difference compared to the control group.\n",
      "\n",
      "The best performing variation is **Test 2**, with a mean improvement of 10.0000.\n"
     ]
    }
   ],
   "source": [
    "    #### Input parameters to calculate your sample size ####\n",
    "control_mean = 50  # Control group mean\n",
    "control_std = 10   # Control group standard deviation\n",
    "control_n = 1000   # Control group sample size\n",
    "\n",
    "variations_data = [\n",
    "    (52, 10, 800),  # Test 1 (mean, std, sample size)\n",
    "    (60, 50, 1000),\n",
    "    (48, 50, 600)\n",
    "]\n",
    "\n",
    "    #### Run the function and print results ####\n",
    "analyze_abn_test_continous(control_mean, control_std, control_n, variations_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
